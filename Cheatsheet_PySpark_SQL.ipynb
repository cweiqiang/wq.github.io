{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cheatsheet-PySpark_SQL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP4K5M87sJvRDB8EuFLt4j8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cweiqiang/wq.github.io/blob/main/Cheatsheet_PySpark_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SparkSQL\n",
        "Spark SQL is Apache Spark's module\n",
        "\n",
        "for working with structured data."
      ],
      "metadata": {
        "id": "4pe2tZwEFMG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Initializing SparkSession\n",
        "\n",
        "A SparkSession can be used create DataFrame, register DataFrame as tables,\n",
        "\n",
        "execute SQL over tables, cache tables, and read parquet files."
      ],
      "metadata": {
        "id": "hRfqFFQiFQr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-oo0VkEEAMJ"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Creating DataFrames"
      ],
      "metadata": {
        "id": "V8vf0Ek9FfDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From RDDs"
      ],
      "metadata": {
        "id": "uG0GEVnQFjPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "TImGdCgRFhXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer Schema"
      ],
      "metadata": {
        "id": "MsrsUOvSFmSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "lines = sc.textFile(\"people.txt\")\n",
        "parts = lines.map(lambda l: l.split(\",\"))\n",
        "people = parts.map(lambda p: Row(name=p[0],age=int(p[1])))\n",
        "peopledf = spark.createDataFrame(people)"
      ],
      "metadata": {
        "id": "ygTRdLArFqa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specify Schema"
      ],
      "metadata": {
        "id": "TDmtbk3KFvsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "people = parts.map(lambda p: Row(name=p[0],\n",
        "                                 age=int(p[1].strip())))\n",
        "\n",
        "schemaString = \"name age\"\n",
        "\n",
        "fields = [StructField(field_name, StringType(), True) for\n",
        "          field_name in schemaString.split()]\n",
        "\n",
        "schema = StructType(fields)\n",
        "\n",
        "spark.createDataFrame(people, schema).show()"
      ],
      "metadata": {
        "id": "-OaiWeooFxs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## From Spark Data Sources"
      ],
      "metadata": {
        "id": "mMEOyTuLGE6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### JSON"
      ],
      "metadata": {
        "id": "tDUIcOyXGG7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"customer.json\")\n",
        "\n",
        "df.show()\n",
        "df2 = spark.read.load(\"people.json\", format=\"json\")"
      ],
      "metadata": {
        "id": "TnizjLTRGGI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parquet files"
      ],
      "metadata": {
        "id": "UUXBugKvGMHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = spark.read.load(\"users.parquet\")"
      ],
      "metadata": {
        "id": "kP_Td7UwGOF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TXT files"
      ],
      "metadata": {
        "id": "D0GqOvDhGP8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = spark.read.text(\"people.txt\")"
      ],
      "metadata": {
        "id": "CMeeWHjeGSai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Filter"
      ],
      "metadata": {
        "id": "c_WdIOGQGV9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Filter entries of age, only keep those records of which the values are >24\n",
        "df.filter(df[\"age\"]>24).show()"
      ],
      "metadata": {
        "id": "t67iP4T_GYKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Duplicate Values"
      ],
      "metadata": {
        "id": "i3qYpjm2GbIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropDuplicates()"
      ],
      "metadata": {
        "id": "82cP4vbFGejI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Queries"
      ],
      "metadata": {
        "id": "SsOqP3LqGf72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "8pKnoDeRGiCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select"
      ],
      "metadata": {
        "id": "XEVdkd3yGjtU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstName\").show() #Show all entries in firstName column\n",
        "\n",
        "df.select(\"firstName\",\"lastName\") \\\n",
        "  .show()\n",
        "\n",
        "df.select(\"firstName\", #Show all entries in firstName, age and type\n",
        "          \"age\", \n",
        "          explode(\"phoneNumber\") \\\n",
        "          .alias(\"contactInfo\")) \\\n",
        "  .select(\"contactInfo.type\", \n",
        "          \"firstName\", \n",
        "          \"age\") \\\n",
        "  .show()\n",
        "\n",
        "df.select(df[\"firstName\"],df[\"age\"]+ 1)  #Show all entries in firstName and age, \n",
        "  .show()                                # add 1 to the entries of age\n",
        "\n",
        "df.select(df['age'] > 24).show() #Show all entries where age >24"
      ],
      "metadata": {
        "id": "A95SNFaAGmEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### When"
      ],
      "metadata": {
        "id": "Hj8Qy2RnHQs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstName\", #Show firstName and 0 or 1 depending on age >30\n",
        "          F.when(df.age > 30, 1) \\ \n",
        "          .otherwise(0)) \\\n",
        "  .show()\n",
        "\n",
        "df[df.firstName.isin(\"Jane\",\"Boris\")] #Show firstName if in the given options\n",
        "              .collect()"
      ],
      "metadata": {
        "id": "zwIoeAxGHRmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Like"
      ],
      "metadata": {
        "id": "96gJnKF0HcYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstName\", #Show firstName, and lastName is TRUE if lastName is like Smith\n",
        "          df.lastName.like(\"Smith\")) \\ \n",
        "  .show()"
      ],
      "metadata": {
        "id": "O3qJ-pGqHdaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Startswith - Endswith"
      ],
      "metadata": {
        "id": "aZgWxX_gHkdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstName\", #Show firstName, and TRUE if lastName starts with Sm\n",
        "          df.lastName \\ \n",
        "            .startswith(\"Sm\")) \\\n",
        "  .show()\n",
        "\n",
        "df.select(df.lastName.endswith(\"th\"))\\ #Show last names ending in th\\\n",
        "  .show()"
      ],
      "metadata": {
        "id": "ZKrN7UnEHnDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sub string"
      ],
      "metadata": {
        "id": "mjgt4eh_H0kf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.firstName.substr(1, 3) \\ #Return substrings of firstName\n",
        "          .alias(\"name\")) \\\n",
        "  .collect()"
      ],
      "metadata": {
        "id": "1kaTu0XYH1-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Between"
      ],
      "metadata": {
        "id": "VEubCTMeH6bL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(df.age.between(22, 24)) \\ #Show age: values are TRUE if between 22 and 24\n",
        "  .show()"
      ],
      "metadata": {
        "id": "ezULP2RqH8Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Add, Update & Remove Columns"
      ],
      "metadata": {
        "id": "wfra7UpCIG3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding Columns"
      ],
      "metadata": {
        "id": "_j4MjE0NIMm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn('city',df.address.city) \\\n",
        "       .withColumn('postalCode',df.address.postalCode) \\\n",
        "       .withColumn('state',df.address.state) \\\n",
        "       .withColumn('streetAddress',df.address.streetAddress) \\\n",
        "       .withColumn('telePhoneNumber', explode(df.phoneNumber.number)) \\\n",
        "       .withColumn('telePhoneType', explode(df.phoneNumber.type))"
      ],
      "metadata": {
        "id": "4LRKHHIrIKjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updating Columns"
      ],
      "metadata": {
        "id": "M0IPM3ucIVcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed('telePhoneNumber', 'phoneNumber')"
      ],
      "metadata": {
        "id": "0YeqHsYvIWBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Columns"
      ],
      "metadata": {
        "id": "XDEaJAQjIX5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(\"address\", \"phoneNumber\")\n",
        "df = df.drop(df.address).drop(df.phoneNumber)"
      ],
      "metadata": {
        "id": "vrxeCXvqIaJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 6: Missing & Replacing Values"
      ],
      "metadata": {
        "id": "DfXzMNJTIen5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.na.fill(50).show() #Replace null values\n",
        "\n",
        "df.na.drop().show() #Return new df omitting rows with null values\n",
        "\n",
        "df.na \\ #Return new df replacing one value with another\n",
        "  .replace(10, 20) \\ \n",
        "  .show()"
      ],
      "metadata": {
        "id": "fBknvYueIgZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 7: GroupBy"
      ],
      "metadata": {
        "id": "LU72TVK_IqMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"age\")\\ #Group by age, count the members in the groups\n",
        "  .count() \\ \n",
        "  .show()"
      ],
      "metadata": {
        "id": "AeTB66WXIrij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 8: Sort"
      ],
      "metadata": {
        "id": "hsUvTCCDIwk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peopledf.sort(peopledf.age.desc()).collect()\n",
        "\n",
        "df.sort(\"age\", ascending=False).collect()\n",
        "\n",
        "df.orderBy([\"age\",\"city\"],ascending=[0,1])\\\n",
        "  .collect()"
      ],
      "metadata": {
        "id": "zPRgk79-Izr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 9: Repartitioning"
      ],
      "metadata": {
        "id": "FdSh3YbFI4GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.repartition(10)\\ #df with 10 partitions\n",
        "  .rdd \\\n",
        "  .getNumPartitions()\n",
        "\n",
        "df.coalesce(1).rdd.getNumPartitions() #df with 1 partition"
      ],
      "metadata": {
        "id": "pjOe-My8I6V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 10: Running Queries Programmatically"
      ],
      "metadata": {
        "id": "h2stZwvRJCQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Registering DataFrames as Views\n"
      ],
      "metadata": {
        "id": "0N49CtVxJF_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "peopledf.createGlobalTempView(\"people\")\n",
        "\n",
        "df.createTempView(\"customer\")\n",
        "\n",
        "df.createOrReplaceTempView(\"customer\")"
      ],
      "metadata": {
        "id": "U3PN7bt-JEOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query Views"
      ],
      "metadata": {
        "id": "kAzkTsjhJJgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = spark.sql(\"SELECT * FROM customer\").show()\n",
        "\n",
        "peopledf2 = spark.sql(\"SELECT * FROM global_temp.people\")\\\n",
        "                 .show()"
      ],
      "metadata": {
        "id": "USZWxAESJLPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 11: Inspect Data"
      ],
      "metadata": {
        "id": "33sBu64nJQ0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes #Return df column names and data types\n",
        "\n",
        "df.show() #Display the content of df\n",
        "\n",
        "df.head() #Return first n rows\n",
        "\n",
        "df.first() #Return first row\n",
        "\n",
        "df.take(2) #Return the first n rows >>> df.schema Return the schema of df\n",
        "\n",
        "df.describe().show() #Compute summary statistics >>> df.columns Return the columns of df\n",
        "\n",
        "df.count() #Count the number of rows in df\n",
        "\n",
        "df.distinct().count() #Count the number of distinct rows in df\n",
        "\n",
        "df.printSchema() #Print the schema of df\n",
        "\n",
        "df.explain() #Print the (logical and physical) plans"
      ],
      "metadata": {
        "id": "8bkhSCsXJR3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 12: Output"
      ],
      "metadata": {
        "id": "NY9fGt0yJYpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Structures"
      ],
      "metadata": {
        "id": "UXVdRY3AJa2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = df.rdd #Convert df into an RDD\n",
        "\n",
        "df.toJSON().first() #Convert df into a RDD of string\n",
        "\n",
        "df.toPandas() #Return the contents of df as Pandas DataFrame"
      ],
      "metadata": {
        "id": "EVa7QFYqJZ8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write & Save to Files\n"
      ],
      "metadata": {
        "id": "djsPc_RyJjrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"firstName\", \"city\")\\\n",
        "  .write \\\n",
        "  .save(\"nameAndCity.parquet\")\n",
        "\n",
        "df.select(\"firstName\", \"age\") \\\n",
        "  .write \\\n",
        "  .save(\"namesAndAges.json\",format=\"json\")"
      ],
      "metadata": {
        "id": "RyIzYVGoJmZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 13: Stopping SparkSession"
      ],
      "metadata": {
        "id": "byd9zgXxJtEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "SbETb9mZJw1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}